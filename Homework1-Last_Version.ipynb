{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:16:12.534253Z",
     "start_time": "2018-01-09T22:16:12.530354Z"
    }
   },
   "source": [
    "# Homework 1: A Simple Sentiment Analysis of Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this homework is to assess your current skills and your ability to solve an unknown problem. To successfully complete this homework, you may use any resources available to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:43:29.993598Z",
     "start_time": "2018-01-09T22:43:29.974919Z"
    }
   },
   "source": [
    "You need to accomplish the following tasks:\n",
    "1. Choose a Twitter API.\n",
    "1. Configure access to the Twitter API\n",
    "2. Identify a trending topic on Twitter.\n",
    "3. Get at least 500 tweets on your trending topic.\n",
    "3. Find lists of stopwords, positive words, and negative words.\n",
    "4. Calculate the ratio of positive to negative words in your sample.\n",
    "    \n",
    "Answer the following questions: \n",
    "* __What is the ratio of positive to negative words on your trending topic?__ \n",
    "* __What is your interpretation of the ratio?__\n",
    "* __What is the managerial insight that you could offer based on your results?__\n",
    "\n",
    "If you use tutorials/code snippets that you find on the internet to complete this task, make sure that you reference them. Also make sure that the Jupyter notebook is free of mistakes, well-documented, and professionally formatted before you submit it.\n",
    "\n",
    "This homework is due on Friday, 12 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Twitter Sentimental Analysis\n",
    "\n",
    "Author: Xiao Zhang\n",
    "\n",
    "Reference link:\n",
    "https://www.geeksforgeeks.org/twitter-sentiment-analysis-using-python/\n",
    "\n",
    "Note: before reviewing the code, I take the \"words\" in the question as \"topics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-09T22:48:15.638542Z",
     "start_time": "2018-01-09T22:48:15.633807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import re\n",
    "import tweepy\n",
    "import twitter\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from twitter import Twitter, OAuth\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_word_file = 'http://localhost:8888/edit/2018%20Python/positive-words.txt'\n",
    "stopwords_file = 'http://localhost:8888/edit/2018%20Python/_stopwords.txt'\n",
    "negative_word_file = 'http://localhost:8888/edit/2018%20Python/negative_words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterConsumer(object):\n",
    "\n",
    "    try:\n",
    "        import json\n",
    "    except ImportError:\n",
    "        import simplejson as json\n",
    "\n",
    "\n",
    "    try:\n",
    "        # My credentials to access Twitter API\n",
    "        consumer_key = 'E5NyOKATic2KVFQD8bFACi7ws'\n",
    "        consumer_secret = 'dHHBhbfpbZNDPZlUDD4ZMWYYdSwpaVbq2tsLPCrHPvZ2pe9etF'\n",
    "        access_token = '940798876210155521-sIOX6DRJ78iI6aYz8pPxNvTEDRHAfxk'\n",
    "        access_token_secret = 'YcB0GVNSzCxMw2QMs2MRucdmI3yOEDSZDTaCMyrotIUM9'\n",
    "\n",
    "        oauth = OAuth(access_token, access_token_secret, consumer_key, consumer_secret)\n",
    "\n",
    "    except:\n",
    "        print(\"Error: Authentication Failed\")    \n",
    "\n",
    "\n",
    "    # Get 500 tweets of certain topic\n",
    "    def get_raw_tweets(searchstr):\n",
    "            resultpage = []\n",
    "            for i in (1,5):\n",
    "                searchresult = api.GetSearch(searchstr, per_page=100, page=i)\n",
    "                resultpage.append(searchresult)\n",
    "            return resultpage\n",
    "\n",
    "\n",
    "    # Apply search api\n",
    "    def get_tweets(query, count = 10):\n",
    "            # Initiate the connection to Twitter REST API\n",
    "            twitter = Twitter(auth=oauth)\n",
    "            # Search for latest tweets about \"query topic\"\n",
    "            tweets= twitter.search.resultpage(q=query)\n",
    "\n",
    "\n",
    "    # Clean data of tweets to remove URL, etc.\n",
    "    def revised_tweet(oauth, tweets):\n",
    "            return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z])|(\\w+:\\\n",
    "        S+)\", \" \", tweets).split())\n",
    "        \n",
    "    \n",
    "    for word in revised_tweet:\n",
    "        # Set up the dict of text and sentiment\n",
    "        new_tweet = {}\n",
    "        # saving key as 'text' of tweet\n",
    "        new_tweet['text'] = tweet.text\n",
    "        # saving key asy 'sentiment' of tweet\n",
    "        new_tweet['sentiment'] = tweet_sentiment(revised_tweet.text)\n",
    "\n",
    "        # appending tweet to tweets list\n",
    "\n",
    "        if tweet.retweet_count > 0:\n",
    "            # if tweet has retweets, ensure that it is appended only once\n",
    "            if new_tweet not in tweets:\n",
    "                revised_tweet.append(new_tweet)\n",
    "        else:\n",
    "            revised_tweet.append(new_tweet)\n",
    "\n",
    "      # return parsed tweets \n",
    "    return new_tweet\n",
    "\n",
    "   # Use function to classify words\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pos_word_list=[]\n",
    "    neu_word_list=[]\n",
    "    neg_word_list=[]\n",
    "\n",
    "    if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "        pos_word_list.append(word)\n",
    "\n",
    "    elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "        neg_word_list.append(word)\n",
    "    else:\n",
    "        neu_word_list.append(word)                \n",
    "\n",
    "    print('Positive :',pos_word_list)        \n",
    "    print('Neutral :',neu_word_list)    \n",
    "    print('Negative :',neg_word_list)\n",
    "    \n",
    "    \n",
    "\n",
    "def main():\n",
    "    # creating object c1 of TwitterClient Class\n",
    "    c1 = TwitterConsumer()\n",
    "    # Get tweets about the past CES event and count = 500\n",
    "    tweets = c1.get_tweets('#CES', 500)\n",
    "    \n",
    "    # Find positive ratio from tweets\n",
    "    ptweets = [tweet for tweet in tweets if new_tweet['sentiment'] == 'positive']\n",
    "    print(\"Positive tweets ratio: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "    \n",
    "    # Find negative ratio from tweets\n",
    "    ntweets = [tweet for tweet in tweets if new_tweet['sentiment'] == 'negative']\n",
    "    print(\"Negative tweets ratio: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "    \n",
    "    \n",
    "    # Find the lists of posword, negword, and stopwords\n",
    "    print(pos_word_list)\n",
    "    print(stop_word_list)\n",
    "    print(neg_word_list)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
